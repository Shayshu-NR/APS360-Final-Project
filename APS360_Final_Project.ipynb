{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APS360 Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pXIAUJp16U8t"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shayshu-NR/APS360-Final-Project/blob/main/APS360_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLdYQtbA8Hep"
      },
      "source": [
        "# Team 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNMbnrZAUX4z"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchtext\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms, utils\n",
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdWvoH9EiWVb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqiBiOwqCtZn"
      },
      "source": [
        " ! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzFGOhBmGK_R"
      },
      "source": [
        "! pip install -U textblob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mVbDL5tH9TF"
      },
      "source": [
        "! python -m textblob.download_corpora"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki-hDarxDA_C"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXZlfj1sOAaf"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! ls ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa90KLriDn0V"
      },
      "source": [
        "! kaggle datasets download -d stefanoleone992/imdb-extensive-dataset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZFYwAOqEAgm"
      },
      "source": [
        "! unzip /content/imdb-extensive-dataset.zip -d '/root/datasets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXIAUJp16U8t"
      },
      "source": [
        "# Baseline Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSbWj-Re6YaT"
      },
      "source": [
        "Extract the necessary info, clean up the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huB0aufiFWdZ"
      },
      "source": [
        "movies = pd.read_csv('/root/datasets/IMDb movies.csv', index_col=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NrZ1xBpJIAW"
      },
      "source": [
        "movies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGNa08vQMAgo"
      },
      "source": [
        "catcols = ['genre', 'budget', 'country', 'duration', 'year', 'avg_vote']\n",
        "df = movies[catcols]\n",
        "not_missing = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdbnq-vyQSE-"
      },
      "source": [
        "not_missing = not_missing[pd.to_numeric(not_missing['year']) > 1980]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYgNyqJRUFs6"
      },
      "source": [
        "no_foreign = not_missing[not_missing['budget'].str[0] == '$']\n",
        "no_foreign['budget'] = no_foreign['budget'].str.replace('$', '')\n",
        "\n",
        "no_foreign['budget'] = no_foreign['budget'].astype('float')\n",
        "no_foreign['duration'] = no_foreign['duration'].astype('float')\n",
        "no_foreign['year'] = no_foreign['year'].astype('float')\n",
        "no_foreign['avg_vote'] = no_foreign['avg_vote'].astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0s7tJi5KZKw"
      },
      "source": [
        "no_foreign"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1hdamR66eVd"
      },
      "source": [
        "Normalize the continuous data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE7M7OdTZkuY"
      },
      "source": [
        "# Normalize budget\n",
        "cont_features = no_foreign[['budget', 'duration', 'year', 'avg_vote']]\n",
        "\n",
        "normalized = no_foreign\n",
        "\n",
        "normalized['budget']  = (normalized['budget'] - normalized['budget'].min()) / (normalized['budget'].max() - normalized['budget'].min()) \n",
        "normalized['duration']  = (normalized['duration'] - normalized['duration'].min()) / (normalized['duration'].max() - normalized['duration'].min()) \n",
        "normalized['year']  = (normalized['year'] - normalized['year'].min()) / (normalized['year'].max() - normalized['year'].min()) \n",
        "normalized['avg_vote']  = (normalized['avg_vote'] - normalized['avg_vote'].min()) / (normalized['avg_vote'].max() - normalized['avg_vote'].min()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92TNNt4KcWYW"
      },
      "source": [
        "normalized_labels  = normalized[['avg_vote']]\n",
        "normalized = normalized[['genre', 'budget', 'country', 'duration', 'year']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Atly_g1K6AI"
      },
      "source": [
        "normalized\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riAIAvbkTwR4"
      },
      "source": [
        "data = pd.get_dummies(normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_vTuYBAT1Co"
      },
      "source": [
        "datanp = data.values.astype(np.float32)\n",
        "labelnp = normalized_labels.values.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syoJZUtY6iFK"
      },
      "source": [
        "Create training and testing data sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIshOflf1Jip"
      },
      "source": [
        "np.random.seed(1000)\n",
        "\n",
        "np.random.shuffle(datanp)\n",
        "np.random.shuffle(labelnp)\n",
        "\n",
        "train_index = int(len(datanp) * 0.9)\n",
        "\n",
        "train_set = datanp[:train_index]\n",
        "test_set = datanp[train_index:]\n",
        "\n",
        "train_label = labelnp[:train_index]\n",
        "test_label = labelnp[train_index:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8I5FPn9Nsx8"
      },
      "source": [
        "test_set.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOiD7Np1Nukc"
      },
      "source": [
        "test_label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E4x5-L-6mNh"
      },
      "source": [
        "Use a premade model to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhoW-FD5PA5p"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate 3 plots: the test and training learning curve, the training\n",
        "    samples vs fit times curve, the fit times vs score curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : estimator instance\n",
        "        An estimator instance implementing `fit` and `predict` methods which\n",
        "        will be cloned for each validation.\n",
        "\n",
        "    title : str\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like of shape (n_samples, n_features)\n",
        "        Training vector, where ``n_samples`` is the number of samples and\n",
        "        ``n_features`` is the number of features.\n",
        "\n",
        "    y : array-like of shape (n_samples) or (n_samples, n_features)\n",
        "        Target relative to ``X`` for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    axes : array-like of shape (3,), default=None\n",
        "        Axes to use for plotting the curves.\n",
        "\n",
        "    ylim : tuple of shape (2,), default=None\n",
        "        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, default=None\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, default=None\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like of shape (n_ticks,)\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the ``dtype`` is float, it is regarded\n",
        "        as a fraction of the maximum size of the training set (that is\n",
        "        determined by the selected validation method), i.e. it has to be within\n",
        "        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n",
        "        sets. Note that for classification the number of samples usually have\n",
        "        to be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "    if axes is None:\n",
        "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    axes[0].set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes[0].set_ylim(*ylim)\n",
        "    axes[0].set_xlabel(\"Training examples\")\n",
        "    axes[0].set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes[0].grid()\n",
        "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes[0].legend(loc=\"best\")\n",
        "\n",
        "    # Plot n_samples vs fit_times\n",
        "    axes[1].grid()\n",
        "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
        "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
        "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
        "    axes[1].set_xlabel(\"Training examples\")\n",
        "    axes[1].set_ylabel(\"fit_times\")\n",
        "    axes[1].set_title(\"Scalability of the model\")\n",
        "\n",
        "    # Plot fit_time vs score\n",
        "    axes[2].grid()\n",
        "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
        "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
        "    axes[2].set_xlabel(\"fit_times\")\n",
        "    axes[2].set_ylabel(\"Score\")\n",
        "    axes[2].set_title(\"Performance of the model\")\n",
        "\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7qa00F2yoTS"
      },
      "source": [
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "model = linear_model.SGDRegressor()\n",
        "model.fit(train_set, train_label)\n",
        "\n",
        "result = model.predict(test_set)\n",
        "\n",
        "\n",
        "accuracy  = 0 \n",
        "loss = 0\n",
        "for i in range(len(result)):\n",
        "\n",
        "\n",
        "  how_close = abs(result[i] - test_label[i])\n",
        "  \n",
        "  if how_close < 0.1 :\n",
        "    accuracy += 1\n",
        "  \n",
        "  loss += (how_close)**2.0\n",
        "\n",
        "plot_learning_curve(model, \"Test\", test_set, test_label)\n",
        "print('Testing data performance', 100 * (accuracy / len(result)), '% correctly predicted')\n",
        "print('Testing data performance', (loss / len(result)), 'Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xAI6E676sBS"
      },
      "source": [
        "The testing accuracy of this model was 48.13%, with a mean squared loss of 0.024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy6_pblCyBx1"
      },
      "source": [
        "# Primary Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nURn_hvKsrz"
      },
      "source": [
        "class MovieDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data, labels):\n",
        "    self.labels = labels\n",
        "    self.data = data\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      # Load data and get label\n",
        "      X = self.data[index]\n",
        "      y = self.labels[index]\n",
        "\n",
        "      return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNTCPqB359Yp"
      },
      "source": [
        "movies = pd.read_csv('/root/datasets/IMDb movies.csv', index_col=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0i9bvhO59_y"
      },
      "source": [
        "catcols = ['genre', 'budget', 'country', 'duration', 'year', 'actors', 'director', 'description', 'avg_vote']\n",
        "df = movies[catcols]\n",
        "not_missing = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9dsia40b0oa"
      },
      "source": [
        "year_dis = []\n",
        "its = []\n",
        "years = []\n",
        "j = 0\n",
        "\n",
        "for i in range(114):\n",
        "  year_dis.append(not_missing[not_missing.year == (1906 + i)].shape[0])\n",
        "  its.append(i + 1906)\n",
        "\n",
        "  num_movs = year_dis[j]\n",
        "  for k in range(num_movs):\n",
        "    years.append(1906 + i)\n",
        "  j+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGYx8kkwbUEG"
      },
      "source": [
        "test = np.array(years)\n",
        "\n",
        "print(len(np.where(test > 1980)[0]) / len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SscsB7la8Yv"
      },
      "source": [
        "plt.hist(years, bins=114)\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of movies\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOl7Gw6ffi8t"
      },
      "source": [
        "unq_genres = np.sort(not_missing['avg_vote'].unique())\n",
        "gen_breakd = []\n",
        "nor_gen = []\n",
        "votes = []\n",
        "j = 0\n",
        "\n",
        "for i in unq_genres:\n",
        "  gen_breakd.append(not_missing[not_missing.avg_vote == i].shape[0])\n",
        "  num_movs = gen_breakd[j]\n",
        "  for k in range(num_movs):\n",
        "    votes.append(i)\n",
        "  j += 1\n",
        "\n",
        "# total = np.sum(gen_breakd)\n",
        "\n",
        "# for i in gen_breakd:\n",
        "#   nor_gen.append(100.0 * i / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRsfQ3MSZGz4"
      },
      "source": [
        "plt.hist(votes, bins=len(unq_genres))\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Number of movies\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXmSd4g26GFa"
      },
      "source": [
        "not_missing = not_missing[pd.to_numeric(not_missing['year']) > 1980]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eLdKUe-6Hza"
      },
      "source": [
        "no_foreign = not_missing[not_missing['budget'].str[0] == '$']\n",
        "no_foreign['budget'] = no_foreign['budget'].str.replace('$', '')\n",
        "\n",
        "no_foreign['budget'] = no_foreign['budget'].astype('float')\n",
        "no_foreign['duration'] = no_foreign['duration'].astype('float')\n",
        "no_foreign['year'] = no_foreign['year'].astype('float')\n",
        "no_foreign['avg_vote'] = no_foreign['avg_vote'].astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2BEEZin6LgN"
      },
      "source": [
        "# Normalize budget\n",
        "cont_features = no_foreign[['budget', 'duration', 'year', 'avg_vote']]\n",
        "\n",
        "normalized = no_foreign\n",
        "\n",
        "normalized['budget']  = (normalized['budget'] - normalized['budget'].min()) / (normalized['budget'].max() - normalized['budget'].min()) \n",
        "normalized['duration']  = (normalized['duration'] - normalized['duration'].min()) / (normalized['duration'].max() - normalized['duration'].min()) \n",
        "normalized['year']  = (normalized['year'] - normalized['year'].min()) / (normalized['year'].max() - normalized['year'].min()) \n",
        "normalized['avg_vote']  = (normalized['avg_vote'] - normalized['avg_vote'].min()) / (normalized['avg_vote'].max() - normalized['avg_vote'].min()) \n",
        "normalized['polarity'] = normalized['description'].apply(lambda x: TextBlob(x).sentiment[0])\n",
        "normalized['subjectivity'] = normalized['description'].apply(lambda x: TextBlob(x).sentiment[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYV1R5MuVr_H"
      },
      "source": [
        "normalized['lead_actor']  = normalized['actors'].apply(lambda x: x.split(\",\")[0])\n",
        "normalized['supporting_actor_1'] = normalized['actors'].apply(lambda x: x.split(\",\")[1] if len(x.split(\",\")) >= 2 else \"\")\n",
        "normalized['supporting_actor_2'] = normalized['actors'].apply(lambda x: x.split(\",\")[2] if len(x.split(\",\")) >= 3 else \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzyyTy_x6PNn"
      },
      "source": [
        "normalized = normalized[['avg_vote','genre', 'budget', 'country', 'duration', 'year', 'polarity', 'subjectivity']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlMRw4EcTRSK"
      },
      "source": [
        "normalized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD8_dcrj6Rww"
      },
      "source": [
        "data = pd.get_dummies(normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICssuemLyF4D"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBP_NVfB6SHE"
      },
      "source": [
        "datanp = data.values.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wUYox-uT6uR"
      },
      "source": [
        "datanp.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9WMh41jclxa"
      },
      "source": [
        "# set the numpy seed for reproducibility\n",
        "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html\n",
        "np.random.seed(50)\n",
        "\n",
        "# todo\n",
        "np.random.shuffle(datanp)\n",
        "\n",
        "train_index = int(len(datanp)*0.70)\n",
        "val_index = int(len(datanp)*0.85)\n",
        "\n",
        "train_set = datanp[:train_index]\n",
        "val_set =  datanp[train_index:val_index]\n",
        "test_set = datanp[val_index:]\n",
        "\n",
        "train_label = datanp[:train_index]\n",
        "val_label =  datanp[train_index:val_index]\n",
        "test_label = datanp[val_index:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtR3BcJWcYTE"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True) \n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQQSUXEOQ0D"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        self.name = \"AutoEncoder\"\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(1958, 1000), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 500),\n",
        "\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(500, 1000), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 1958),\n",
        "            nn.Sigmoid() # get to the range (0, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFNtLWOyOqOp"
      },
      "source": [
        "def zero_out_rating(records):\n",
        "    records[:, 0] = 0\n",
        "    return records"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSdwPB0xP63G"
      },
      "source": [
        "# For the autoencoder\n",
        "def get_accuracy(model, data_loader):\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    for item in data_loader: # minibatches\n",
        "        inp = item.detach().numpy()\n",
        "        out = model(zero_out_rating(item.clone())).detach().numpy()\n",
        "        for i in range(out.shape[0]): # record in minibatch\n",
        "            if out[i][0] <= inp[i][0] + 0.10 and out[i][0] >= inp[i][0] - 0.10:\n",
        "              acc = acc + 1\n",
        "            total += 1\n",
        "    return acc / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHFk--idegWO"
      },
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, learning_rate, epoch)\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SBDeiNOg4F"
      },
      "source": [
        "def train(model, train_loader, valid_loader, batch_size=32, num_epochs=5, learning_rate=1e-4):\n",
        "    \"\"\" Training loop. You should update this.\"\"\"\n",
        "    torch.manual_seed(42)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "    n = 0 # the number of iterations\n",
        "    k = 0\n",
        "    j = 0\n",
        "    val_iters, val_losses, acc_iters = [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        for data in train_loader:\n",
        "            #print(data)\n",
        "            datam = zero_out_rating(data.clone()) # zero out one categorical feature\n",
        "            recon = model(datam)\n",
        "            loss = criterion(recon[:,0], data[:,0])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            n += 1\n",
        "            \n",
        "\n",
        "                #Calculating validation loss at the end of each epoch\n",
        "        for data in valid_loader:\n",
        "          datam = zero_out_rating(data.clone()) # zero out one categorical feature\n",
        "          recon = model(datam)\n",
        "          loss = criterion(recon[:,0], data[:,0])\n",
        "\n",
        "          # save the current training information\n",
        "          val_iters.append(k)\n",
        "          val_losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "          k += 1\n",
        "\n",
        "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        # plotting the training loss every 20 iterations\n",
        "        plt.title(\"Training Losses\")\n",
        "        plt.plot(iters, losses, label=\"Train\")\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.show()\n",
        "        # plotting validation loss \n",
        "        plt.title(\"Validation Losses\")\n",
        "        plt.plot(val_iters, val_losses, label=\"Validation\")\n",
        "        plt.xlabel(\"Validation Iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        #Calculating training accuracy and validation accuarcy \n",
        "        acc_iters.append(j)\n",
        "        j += 1\n",
        "        val_acc.append(get_accuracy(model,valid_loader))\n",
        "        train_acc.append(get_accuracy(model,train_loader))\n",
        "        plt.title(\"Training Curve\")\n",
        "        plt.plot(acc_iters, train_acc, label=\"Training\")\n",
        "        plt.plot(acc_iters, val_acc, label=\"Validation\")    \n",
        "        plt.xlabel(\"Every 20 Iterations\")\n",
        "        plt.ylabel(\"Validation Accuracy\")\n",
        "        plt.legend(loc='best')\n",
        "        plt.show()\n",
        "        \n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZdTKbKlOYzg"
      },
      "source": [
        "MyModel = AutoEncoder()\n",
        "train(MyModel, train_loader, val_loader,32 ,10, 1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7DDwYbSdzZS"
      },
      "source": [
        "model = AutoEncoder()\n",
        "model_path = model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(model.name,32, 0.00001,9)\n",
        "state = torch.load(model_path)\n",
        "model.load_state_dict(state)\n",
        "test_loader = torch.utils.data.DataLoader(test_set)\n",
        "test_accuracy = get_accuracy(model, test_loader)\n",
        "print(\"Test Accuracy: \", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5hXVcsslImw"
      },
      "source": [
        "# Godzilla Vs Kong movie from IMDb\n",
        "# https://www.imdb.com/title/tt5034838/\n",
        "godzilla_desc = 'The epic next chapter in the cinematic Monsterverse pits two of the greatest icons in motion picture history against one another - the fearsome Godzilla and the mighty Kong - with humanity caught in the balance.'\n",
        "godzilla_year = (2021 - no_foreign['year'].min()) / (2021 - no_foreign['year'].min()) \n",
        "godzilla_dur = (113 - no_foreign['duration'].min()) / (no_foreign['duration'].max() - no_foreign['duration'].min()) \n",
        "godzilla_bud = (168000000- no_foreign['budget'].min()) / (no_foreign['budget'].max() - no_foreign['budget'].min())\n",
        "godzilla_pol = TextBlob(godzilla_desc).sentiment[0]\n",
        "godzilla_sub = TextBlob(godzilla_desc).sentiment[1]\n",
        "\n",
        "# AI Adventures \n",
        "ai_desc = 'A wild ride filled with triumph and dispair. Four students, one project, will they be able to pass this course?'\n",
        "ai_year = (1981 - no_foreign['year'].min()) / (2021 - no_foreign['year'].min()) \n",
        "ai_dur = (8 - no_foreign['duration'].min()) / (no_foreign['duration'].max() - no_foreign['duration'].min()) \n",
        "ai_bud = (16000- no_foreign['budget'].min()) / (no_foreign['budget'].max() - no_foreign['budget'].min())\n",
        "ai_pol = TextBlob(ai_desc).sentiment[0]\n",
        "ai_sub = TextBlob(ai_desc).sentiment[1]\n",
        "\n",
        "# Create tensor to hold movie data\n",
        "demo_tensor = torch.zeros((3, 1958))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJdDA4i_glQl"
      },
      "source": [
        "jl_desc = \"Determined to ensure Superman's ultimate sacrifice was not in vain, Bruce Wayne aligns forces with Diana Prince with plans to recruit a team of metahumans to protect the world from an approaching threat of catastrophic proportions.\"\n",
        "jl_year = 1\n",
        "jl_dur = (242 - no_foreign['duration'].min()) / (no_foreign['duration'].max() - no_foreign['duration'].min()) \n",
        "jl_bud = (300000000- no_foreign['budget'].min()) / (no_foreign['budget'].max() - no_foreign['budget'].min())\n",
        "jl_pol = TextBlob(jl_desc).sentiment[0]\n",
        "jl_sub = TextBlob(jl_desc).sentiment[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFhuQvWl0wQt"
      },
      "source": [
        "# Fill in tensor with cleaned data\n",
        "demo_tensor[0, 0] = godzilla_bud\n",
        "demo_tensor[0, 1] = godzilla_dur\n",
        "demo_tensor[0, 2] = godzilla_year\n",
        "demo_tensor[0, 3] = godzilla_pol\n",
        "demo_tensor[0, 4] = godzilla_sub\n",
        "demo_tensor[0, 95] = 1\n",
        "demo_tensor[0, 1588] = 1\n",
        "\n",
        "demo_tensor[1, 0] = ai_bud\n",
        "demo_tensor[1, 1] = ai_dur\n",
        "demo_tensor[1, 2] = ai_year\n",
        "demo_tensor[1, 3] = ai_pol\n",
        "demo_tensor[1, 4] = ai_sub\n",
        "demo_tensor[1, 307] = 1\n",
        "demo_tensor[1, 1588] = 1\n",
        "\n",
        "demo_tensor[2, 0] = jl_bud\n",
        "demo_tensor[2, 1] = jl_dur\n",
        "demo_tensor[2, 2] = jl_year\n",
        "demo_tensor[2, 3] = jl_pol\n",
        "demo_tensor[2, 4] = jl_sub\n",
        "demo_tensor[2, 95] = 1\n",
        "demo_tensor[2, 1588] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiA5uThY21dy"
      },
      "source": [
        "# Run Model on test data and extract the avg_vote column\n",
        "model = AutoEncoder()\n",
        "model_path = model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(model.name,32, 1e-5, 9)\n",
        "state = torch.load(model_path)\n",
        "model.load_state_dict(state)\n",
        "\n",
        "godzilla_result = model(demo_tensor[0])[0]\n",
        "ai_result = model(demo_tensor[1])[0]\n",
        "jl_result = model(demo_tensor[2])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ODhv3R3S3j"
      },
      "source": [
        "# Unnormalize the data\n",
        "godzilla_rating = (godzilla_result * (no_foreign['avg_vote'].max() - no_foreign['avg_vote'].min())) + no_foreign['avg_vote'].min()\n",
        "ai_rating = (ai_result * (no_foreign['avg_vote'].max() - no_foreign['avg_vote'].min())) + no_foreign['avg_vote'].min()\n",
        "jl_rating = (jl_result * (no_foreign['avg_vote'].max() - no_foreign['avg_vote'].min())) + no_foreign['avg_vote'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZNh-Xde36LV"
      },
      "source": [
        "# Final results\n",
        "print(\"Godzilla Vs. Kong predicted rating:\", round(float(godzilla_rating),1))\n",
        "print(\"Justice league predicted rating:\", round(float(jl_rating), 1))\n",
        "print(\"AI Adventures predicted rating:\", round(float(ai_rating),1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}